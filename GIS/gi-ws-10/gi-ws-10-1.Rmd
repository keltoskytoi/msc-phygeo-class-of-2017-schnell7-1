---
title: "da-ws10-1"
author: "Laura Giese, Johannes Schnell, Alena Schmid"
date: "30 Januar 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Aufgabe:
Einzelbaumerkung mit Hilfe verschiedneer Berechnungsmethoden (dalponte und watershed)

Herangehensweise:
mit der funktion lidR::lastrees lassen wir beide Methoden über ein normalisiertes Canopzheight modell laufen. und versuchen die auf dise weise ermittelte Baumanzahl mit einer vor Ort durchgeführten Messung zu vergleichen, als auch visuell ein zu schätzen ob der Algorythmus "ansprechende" Ergebnisse liefert oder Strukturen offenbart die "baumuntypisch" sind .

```{r, echo = TRUE, eval = FALSE}
#### SKRIPT for Single Tree Detection with LidR - Sensitivity Analysis####
#***1. create dtm and normalized chm ***2. clip las file and chm ***3. single tree detection


input = "C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/input/"
output = "C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/output/"
temp = "C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/temp/"

#load packages
#install.packages("lidR", dependencies = T)
library(lidR)
library(raster)
#install.packages("raster")
library(rgdal)
library(maptools)
library(png)

## try http:// if https:// URLs are not supported
#source("https://bioconductor.org/biocLite.R")
#biocLite("EBImage")
#install.packages("EBImage")
library(EBImage)

#------------------------------------------------------------###
###-----------create dtm and normalized chm------------------###
#------------------------------------------------------------###
#script for generating normalized chm, method = k nearest neighbours "knnidw"
#install libraries LidR, raster, rgdal, png, maptools
#input: .las or .laz file(s), they are stored in input folder
#output: digital terrain model, normalized canopy hiegth model
#memorylim: the bigger the las data set, the more memory you need (min: 2.000.000), def = 5000000
#cellsize: resolution [m], def = 1
#smooth: mean smoothing, 3x3 focal window, yes = TRUE, no = FALSE, def = T 

#function
dtmANDchm = function(input = input,
                     output = output,
                     cellsize = 1,
                     memorylim = 5000000,
                     smooth = TRUE,
                     overwrite = TRUE) {
  
  #load libraries
  library(lidR)
  library(raster)
  library(rgdal)
  library(maptools)
  library(png)
  
  #load lasfiles in one point cloud
  #make sure that input folder contains only the las files you need for your point cloud
  catalog = catalog(paste0(input))
  las = readLAS(catalog, select = "xyzc")
  
  #change projection
  las@crs@projargs<- c("+proj=utm +zone=32 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0+units=m +no_defs")
  #las
  plot(las, bg = "black")
  
  #dtm
  dtm1 = grid_terrain(las, res = cellsize, method = "knnidw", k = 10)
  plot(dtm1)
  dtm = as.raster(dtm1)
  dtm@crs@projargs<- c("+proj=utm +zone=32 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0+units=m +no_defs")
  dtm
  writeRaster(dtm, file = paste0(output, "dtm_out.tif"), overwrite = overwrite)
  
  #normalize
  dtm = raster(paste0(output, "dtm_out.tif"))
  las = readLAS(catalog, select = "xyz")
  lasnormalize(las, dtm)
  #plot(las)
  
  # compute a canopy image
  memory.limit(memorylim)
  chm = grid_canopy(las, res = cellsize, subcircle = 0.1, na.fill = "knnidw", k = 4)
  chm = as.raster(chm)
  chm@crs@projargs<- c("+proj=utm +zone=32 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0+units=m +no_defs")
  plot(chm)
  
  # smoothing post-process (e.g. 2x mean, 3x3 matrix)
  if (smooth == TRUE){
    kernel = matrix(1,3,3)
    chm = raster::focal(chm, w = kernel, fun = mean)
    chm = raster::focal(chm, w = kernel, fun = mean) 
  }else{
    print("no smoothing")
  }
  
  raster::plot(chm, col = height.colors(50)) # check the image
  
  #save output
  writeRaster(chm, file = paste0(output, "chm_out.tif"), overwrite = overwrite)
}

dtmANDchm(input, output)

####----------------------------------------------###
####----------------clip--------------------------###
####----------------------------------------------###
#setwd("C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/input")
#path to input directory containing las files to be clipped
input = "C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/input/"
#path to output directory containing generated chm (see function "dtmANDchm()")
output = "C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/output/"
#path to directory where cropped files will be saved
#there should be no las file called "las_cropped.las" in the temp directory
temp = "C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/temp/"
#load chm
chm = raster(paste0(output, "chm_out.tif"))

#function
clipdata = function(input = input,
                    temp = temp,
                    xmin = xmin,
                    xmax = xmax,
                    ymin = ymin,
                    ymax = ymax,
                    chm = chm,
                    overwrite = FALSE) {
  #load lasfiles in one point cloud
  #make sure that input folder contains only the las files you need for your point cloud
  catalog = catalog(paste0(input))
  las = readLAS(catalog, select = "xyz")
  
  #clip las files to extent xmin = 477425.0 xmax = 477710.0 ymin = 5631990.0 ymax = 5632150.0
  mrect = matrix(c(xmin, xmax, ymin, ymax), ncol = 2)
  las = las %>% lasclip("rectangle", mrect)
  plot(las, bg = "black", trim)
  #save cropped lasfile
  writeLAS(las, file = paste0(temp, "las_cropped.las"))
  #writeLAS(las_cl, file = "las_clip.las")
  
  ##for sensivity analysis crop chm and las data to small extent
  ##create matrix for clop with shape file
  coords = matrix(c(xmin, ymax,
                    xmax, ymax,
                    xmax, ymin,
                    xmin, ymin), ncol = 2, byrow = TRUE)
  
  #create polygon shape file for crop chm
  P1 = Polygon(coords)
  Ps1 = SpatialPolygons(list(Polygons(list(P1), ID = "a")), proj4string=CRS("+proj=utm +zone=32 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0+units=m +no_defs"))
  plot(Ps1, axes = T)
  
  #->load dtm (created in "Lichtungen")
  chm@crs@projargs<- c("+proj=utm +zone=32 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0+units=m +no_defs")
  
  #crop to same extent as las_cl
  chm_cr = crop(chm, Ps1)
  plot(chm_cr)
  writeRaster(chm_cr, file = paste0(temp, "chm_cropped.tif"), overwrite = overwrite)
}


##clip
clipdata(input = input, temp = temp, xmin = 477393.0, xmax = 477461.00, ymin = 5631938.0, ymax = 5632004.0, chm = chm, overwrite = FALSE)

#----------------------------------------------------------------------#
###--------------------------single tree detection-------------------###
#----------------------------------------------------------------------#
#setwd("C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/input")
input = "C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/input/"
output = "C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/output/"
temp = "C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/temp/"

#load chm
chm = raster(paste0(temp, "chm_cropped.tif"))
#load lasfiles in one point cloud
#make sure that input (temp) folder contains only the las files you need for your point cloud
catalog = catalog(paste0(temp))
las = readLAS(catalog, select = "xyz")
#change projection
las@crs@projargs<- c("+proj=utm +zone=32 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0+units=m +no_defs")

#parameter = vector for method parameters: 
#method dalponte2016: par = c(5,7,10,15,20,25) (Kronendurchmesser)
#method watershed: par = c(5:10) (min. Treehight)
#method Li2012 is not tested as there is no possibility to produse a shape file

#method: algorythm for segmentation: "dalponte2016" or "watershed"

#function
SensitivityAnalysis = function(chm = chm,
                     las = las,
                     output = output,
                     treeheight = treeheight,
                     crowndm = NULL,
                     method = method,
                     overwrite = TRUE) {
  
  #load libraries
  library(lidR)
  library(raster)
  library(rgdal)
  library(maptools)
  library(png)
  library(EBImage)
    
    if (method == "dalponte2016"){
      # 1. way of segmentation: dalponte
      # DIST: crown diameter, th = hight below which pixel cannot me a crown, def = 2
      SensAnalysisFiles = matrix(NA, 36, 5)
      x = 0
      
      for (i in treeheight){
        for (j in crowndm){
        t1 = Sys.time()
        extra = lastrees(las, "dalponte2016", chm, th = i, DIST = j, extra = TRUE)
        t2 = Sys.time()
        crown.shp <- rasterToPolygons(extra$Crown, dissolve = TRUE)
        writeOGR(crown.shp, paste0(output, "crown", i,"_", j,"_", method, ".shp"), 
                paste0(basename(paste0(output, "crown", i,"_", j,"_", method, ".shp"))), 
                driver = "ESRI Shapefile", overwrite = overwrite)
        Maxima.shp <- rasterToPolygons(extra$Maxima, dissolve = TRUE)
        writeOGR(Maxima.shp, paste0(output, "Maxima", i,"_", j,"_", method,".shp"), 
                paste0(basename(paste0(output, "Maxima", i,"_", j,"_", method, ".shp"))), 
                driver = "ESRI Shapefile", overwrite = overwrite)
        print("dalponte2016")
        x = x+1
        SensAnalysisFiles[x,1] = paste0("Maxima", i,"_", j,"_", method, ".shp")
        SensAnalysisFiles[x,2] = method
        SensAnalysisFiles[x,3] = i
        SensAnalysisFiles[x,4] = j
        SensAnalysisFiles[x,5] = t2-t1
        
        }
      }
      
    }else if(method == "watershed"){
      SensAnalysisFiles = matrix(NA, 6, 5)
      x = 0
      #2. way of segmentation: watershed
      #th: hight below which pixel cannot me a crown, def = 2
      for (i in treeheight){
        t1 = Sys.time()
        extra = lastrees(las, "watershed", chm, th = i, extra = TRUE)
        t2 = Sys.time()
        extra.shp <- rasterToPolygons(extra, dissolve = TRUE)
        writeOGR(extra.shp, paste0(output, "extra", i,"_", method, ".shp"), 
                paste0(basename(paste0(output, "extra", i,"_", method, ".shp"))), 
                driver = "ESRI Shapefile", overwrite = overwrite)
        print("watershed")
        x = x+1
        SensAnalysisFiles[x,1] = paste0("extra", i,"_", method, ".shp")
        SensAnalysisFiles[x,2] = method
        SensAnalysisFiles[x,3] = i
        SensAnalysisFiles[x,5] = t2-t1
    }
    
  }
  return(SensAnalysisFiles)
}


methvar = c(1:2)
for (l in methvar){
  if (l == 1){
    SensAnalysisFiles_d = SensitivityAnalysis(chm = chm, las = las, output = output, 
                                              treeheight = c(5:10), 
                                              crowndm = c(5,7,10,15,20,25), 
                                              method = "dalponte2016", overwrite = TRUE)
  }else if(l == 2){
    SensAnalysisFiles_w = SensitivityAnalysis(chm = chm, las = las, output = output, 
                                              treeheight = c(5:10), 
                                              method = "watershed", overwrite = TRUE)
  }
}

sa_files<- rbind(SensAnalysisFiles_d, SensAnalysisFiles_w)
colnames(sa_files)<- c("filename", "method", "mintreeheight", "crowndiameter", "time")
write.table(sa_files, file = paste0(output, "SensAnalysisFiles_out.txt"), sep =",")
```
#----------------------------------------------------------------------#


Nachfolgend die Resultate:
Die Punkte in der dalponte-Darstellung stehen für den höchsten Punkt des "erkannten" Baumes. Diese Methode scheint offentsichtlich fehlerbehaftet, da viele Bäume in den Lücken noch sichtbar sind (sofern LAS und RGB aufnahmen korrekt übereinander liegen)

In der Watershed-Darstellung lassen sich auch Lücken erkennen (dunklere Umrandung), diese decken sich aber eher mit dem visuellen Eindruck des RGB-Bildes. Manche Strukturen sehen tatsächlich recht baumig aus zB im rechten oberen Quandranten innerhalb der Lücke, andere scheinen eher mehrere Bäume zu einewm Objekt zusammengefasst zu haben.

Die Dalpontemethode hat darüber hinaus ungefähr 3-4 mal soviele Bäume gezählt als die watershed-Methode. 

Fazit:
Die Einzelbaumerkennung innerhalb eines Waldes ist mit diesen methoden nur unzureichend und kann allenfalls als grober Schätzwert betrachtet werden. Für eine Baumerkennung in lichteren Gebieten scheint die watershed-Methode jedoch bessere Anhaltspunkte zu liefern
#plot results:
```{r, echo = TRUE}
library(png)
setwd("C:/Users/Laura/Documents/Uni/Rmsc/Data/GIS/POINTCLOUD_processing/Einzelbaum/input")

img <- readPNG("dalponte_th10_und_cd5_darunter_th5_und_cd25.png")
plot(1:1, type='n', xaxt="n", yaxt="n", xlab="", ylab = "", main = "dalponte_th5graue_linien_darunter_th10schwarze_linien")

lim <- par()
rasterImage(img, lim$usr[1], lim$usr[3], lim$usr[2], lim$usr[4])

img <- readPNG("watershed_th5graue_linien_darunter_th10schwarze_linien.png")
plot(1:1, type='n', xaxt="n", yaxt="n", xlab="", ylab = "", main = "watershed_th5graue_linien")

lim <- par()
rasterImage(img, lim$usr[1], lim$usr[3], lim$usr[2], lim$usr[4])
```

